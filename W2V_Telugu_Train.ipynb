{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be50bb3-cee0-4250-9986-700a01999ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec81b4-636f-49a4-b0a4-f70d41a5c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc45ab-b1b6-40ce-99ce-4ed7d0e3ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path):\n",
    "    \"\"\"Read the corpus from a text file.\"\"\"\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            tokens = line.lower().strip().split()\n",
    "            if tokens:\n",
    "                sentences.append(tokens)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a0d78-5b26-47fc-9e0b-3999c578629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec_model(sentences, output_model_path):\n",
    "    \"\"\"Train a Word2Vec model using CBOW with hierarchical softmax.\"\"\"\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    \n",
    "    model = Word2Vec(\n",
    "        vector_size=300,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        sg=0,                 # CBOW model\n",
    "        hs=1,                 # Use hierarchical softmax\n",
    "        workers=cores,\n",
    "        alpha=0.025,\n",
    "        min_alpha=0.0001,\n",
    "        sample=1e-5\n",
    "    )\n",
    "    \n",
    "    print(\"Building vocabulary...\")\n",
    "    model.build_vocab(sentences)\n",
    "    \n",
    "    print(f\"Training model on {len(sentences)} sentences...\")\n",
    "    model.train(\n",
    "        sentences,\n",
    "        total_examples=model.corpus_count,\n",
    "        epochs=10\n",
    "    )\n",
    "    \n",
    "    # Save the full model\n",
    "    model.save(output_model_path)\n",
    "    print(f\"Full model saved to {output_model_path}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e325b3b-ee90-41c8-ae64-6a71ed7ab60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_word2vec_format(model, output_path):\n",
    "    \"\"\"\n",
    "    Save the embeddings in Word2Vec text format.\n",
    "    This is a widely used format compatible with many NLP tools.\n",
    "    \"\"\"\n",
    "    model.wv.save_word2vec_format(output_path, binary=False)\n",
    "    print(f\"Embeddings saved in Word2Vec text format to {output_path}\")\n",
    "    \n",
    "    # Also save in binary format for faster loading\n",
    "    binary_path = output_path + '.bin'\n",
    "    model.wv.save_word2vec_format(binary_path, binary=True)\n",
    "    print(f\"Embeddings saved in Word2Vec binary format to {binary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c0de2-4e55-4aad-be61-d4f053e83f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"te.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492ec0b-041a-4d23-9ef5-141bae97f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"word2vec_cbow_hs_model.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c32736-ad76-4ce3-800c-b25c5018de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_prefix = \"word_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5ad98-d970-4333-8d38-ab5e12593151",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = read_corpus(corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62412e16-2172-4145-8861-2907b2192fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0334f-75ae-418e-9c44-a31961c2c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd381dc-7bda-4230-a11e-5147646b03d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train_word2vec_model(sentences, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc1fcf-fc6f-41e3-8d2e-2d6913921fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_word_analogy(model, word1, word2, word3):\n",
    "    \"\"\"\n",
    "    Perform word analogy: word1 is to word2 as word3 is to X\n",
    "    Example: man is to king as woman is to X (queen)\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained Word2Vec model\n",
    "    - word1, word2, word3: Words for the analogy\n",
    "    \n",
    "    Returns:\n",
    "    - List of tuples containing the most similar words and their similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if all words are in the vocabulary\n",
    "        for word in [word1, word2, word3]:\n",
    "            if word not in model.wv.key_to_index:\n",
    "                print(f\"Warning: '{word}' not in vocabulary\")\n",
    "                return []\n",
    "        \n",
    "        # Perform the analogy\n",
    "        result = model.wv.most_similar(positive=[word2, word3], negative=[word1], topn=5)\n",
    "        return result\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e}. One of the words is not in vocabulary.\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b091d37-a5de-466f-baab-d28a61fb7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_word_analogy(model, \"పురుషుడు\", \"రాజు\", \"స్త్రీ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b080fd-691f-422c-8e95-ad3da1fe81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953e506-3db0-49cc-8315-eb1cefea5c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
